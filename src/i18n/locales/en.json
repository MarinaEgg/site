{
  "navigation": {
    "home": "Home",
    "lab": "Lab",
    "learn": "Learn",
    "contact": "Contact"
  },
  "hero": {
    "title": "Make AI agents your competitive advantage",
    "subtitle": "Securely connect AI to your company's knowledge with agents that plan, act, and empower every team with trusted.",
    "cta": "Start building",
    "labLink": "EggOn Lab — The team dedicated to making AI agents fully insurable."
  },
  "collection": {
    "title": "CASE STUDIES",
    "subtitle": "Companies choose to build with EggOn for an unfair competitive advantage. Our agents are trusted by leading firms in legal, aerospace, and finance. Stay informed — request a quote.",
    "cta": "Request a Quote",
    "core": {
      "contractRiskAnalysis": {
        "title": "Contract Risk Analysis Agent",
        "context": "Legal / Risk Review",
        "body": "Analyze a commercial contract and highlight clauses that pose legal risks (e.g., indemnities, termination, governing law). Provide a summary with explanations and recommendations."
      },
      "caseLawResearch": {
        "title": "Case Law Research Agent",
        "context": "Legal / Case Research",
        "body": "Search and summarize relevant case law related to a specific legal question, including links and jurisdiction-specific reasoning."
      },
      "meetingMemory": {
        "title": "Meeting Summary Agent",
        "context": "Productivity / Project Management",
        "body": "Listen to or analyze meeting notes, extract key points, and automatically convert decisions and discussions into actionable tasks with assigned owners and deadlines."
      },
      "internalWikiBuilder": {
        "title": "Internal Wiki Builder Agent",
        "context": "Knowledge Management / Documentation",
        "body": "Create and update a private internal Wiki by scanning documents and internal conversations. Automatically tag and categorize entries."
      },
      "promptImprovementAgent": {
        "title": "Prompt Improvement Agent",
        "context": "AI / Continuous Enhancement",
        "body": "Analyze prompts used, identify weaknesses, and generate optimized versions to improve the accuracy, clarity, and consistency of AI model responses."
      },
      "contractReviewAgent": {
        "title": "Contract Review Agent",
        "context": "Legal / Quality Control",
        "body": "Check consistency, compliance, and key terms in contract documents, generating annotations and improvement suggestions."
      },
      "quotationGenerator": {
        "title": "Quotation Generator Agent",
        "context": "Sales / B2B Quotations",
        "body": "Generate and send professional client-ready quotations based on product configurations, pricing rules, and customer data."
      },
      "competitiveIntelligenceAgent": {
        "title": "Competitive Intelligence Agent",
        "context": "Strategy / Market Intelligence",
        "body": "Automatically monitor competitor activity (appointments, new specialties, partnerships), analyze pricing strategies and innovative service offers, and identify positioning in new markets or emerging technologies."
      },
      "technologyIntelligenceAgent": {
        "title": "Technology Intelligence Agent",
        "context": "R&D / Strategy",
        "body": "Weekly summaries of key news and trends in a selected technology sector, including key sources, highlights, and regulatory updates."
      },
      "billingAndPaymentAgent": {
        "title": "Billing and Payment Tracking Agent",
        "context": "Finance / Legal Accounting",
        "body": "Automatically generate invoices from time entries or flat fees, send personalized payment reminders, track payment status, and manage trust retainer balances. Integrates with Clio, Xero, or QuickBooks."
      },
      "interactiveFinancialReportingAgent": {
        "title": "Interactive Financial Reporting Agent",
        "context": "Finance / Performance Management",
        "body": "Produce a dynamic dashboard showing profitability by case, lawyer, or client, with natural language query capability (e.g., 'Show margin on litigation cases since January'). Integrates with Power BI or Tableau, conversational LLM interface."
      }
    }
  },
  "legalStack": {
    "subtitle": "WHY EGGON",
    "title": "Trust a team with expertise in your field",
    "description": "Eggon combines deep legal expertise with real AI engineering to deliver trusted, integrated solutions tailored to your operational challenges.",
    "stackTitle": "THE LEGAL AGENT STACK",
    "benefits": [
      {
        "title": "Connected to Your World",
        "description": "We build AI agents and systems focused on the legal domain and parts of the defense industry. Some of our team members come from leading legaltech companies or industry experts who know your environment."
      },
      {
        "title": "Solves Your Toughest Challenges", 
        "description": "From simple tasks to complex reasoning, we connect your documents, tools, and AI with ROI in mind — and we stay aligned with your mission."
      },
      {
        "title": "From Complexity to Clarity",
        "description": "We transform legal and technical complexity into clear, actionable outputs — with an experienced team that manages the project and stays by your side."
      },
      {
        "title": "Real AI Engineering",
        "description": "We build, develop, and deploy real AI systems. From a simple agent in your Copilot Studio to a more advanced custom AI system using our chat interface, our private API, and a vector database built for you"
      }
    ],
    "stackComponents": [
      {
        "badge": "RAG",
        "title": "Connect Your Internal Databases to a Large Language Model (RAG)",
        "description": "We connect your case files, contracts, and legal databases directly to AI models. Your confidential data remains secure while you get instant, accurate answers from your entire knowledge base."
      },
      {
        "badge": "AI Agents",
        "title": "Build Your AI Agents",
        "description": "We develop AI agents—using Microsoft Azure Studio or your own technical environment—that manage your specific legal workflows. Process sensitive documents with models that never leave your infrastructure."
      },
      {
        "badge": "AI Multi-Agents",
        "title": "Build Multi-Agent Systems",
        "description": "Automate complex legal processes with multiple AI agents working together. Delegate tasks end-to-end, from document review to drafting and legal research."
      },
      {
        "badge": "Private AI",
        "title": "Chatbot Interface & API Connectivity",
        "description": "Ask questions in plain language and get instant answers from all your files. Automatically analyze contracts, process legal documents, and assist with legal research—fully integrated with your existing databases."
      }
    ]
  },
  "learn": {
    "title": "Working EggOn Lab",
    "intro1": "EggOn Lab is dedicated to the governance and traceability of artificial intelligence agents through a next-generation orchestrator.",
    "intro2": "We are building a future where professionals — especially in law, finance, and healthcare — can deploy AI agents that are certified compliant, auditable, and insurable.",
    "intro3": "We are engineers and builders who have worked for some of the most secure tech companies, including iManage, and for industry leaders as Traceability System Experts and Quality Engineers.",
    "legitimacy": {
      "title": "Legitimacy in AI Is About More Than Right or Wrong Answers",
      "paragraph1": "AI capabilities are advancing at an unprecedented pace, but one major problem remains: opacity.",
      "paragraph2": "This opacity is even more concerning as AI enters sectors that are not like any other industries: justice and healthcare. These are the foundations of a free and fair society.",
      "paragraph3": "Every day, courts make decisions that change the course of human lives. Such decisions demand empathy, experience, and context — but also a process that feels legitimate to those affected.",
      "paragraph4": "No family should ever wonder if they lost custody because of a poorly calibrated algorithm. No patient should ever doubt that their treatment was decided after genuine human evaluation.",
      "paragraph5": "The real issue isn't simply whether AI gives the right or wrong answer — it's doubt. And once doubt sets in, it erodes trust and undermines the legitimacy of our systems."
    },
    "aiForEveryone": {
      "title": "AI That Works for Everyone",
      "paragraph1": "Knowledge of how AI agents operate and make decisions must not remain concentrated in a few labs.",
      "paragraph2": "This lack of transparency slows adoption in high-responsibility professions, and the absence of explainability makes insuring AI-driven processes impossible.",
      "paragraph3": "To bridge this gap, we created N.O.G (Nested Orchestration & Governance) — a platform designed to understand, audit, and certify AI agents."
    },
    "principles": {
      "title": "Solid Legitimacy Matters",
      "explicability": {
        "title": "Explicability",
        "description": "Every task executed by an AI agent must be understandable and explainable. Users must be able to trace the full reasoning and verify its legitimacy."
      },
      "accessibility": {
        "title": "Accessibility",
        "description": "Explainability only matters if it's shared. Results and supporting evidence must be easy to access for everyone impacted by a decision."
      },
      "recall": {
        "title": "Recall",
        "description": "If bias, error, or manipulation is detected, the system must allow for immediate recall — just like product recalls in critical industries. Governed AI should never be irreversible."
      },
      "speed": {
        "title": "Speed",
        "description": "Compliance must not slow innovation. Explainable AI should be as fast as it is powerful, accelerating adoption while building trust."
      }
    },
    "growth": {
      "title": "Growth Step by Step",
      "paragraph1": "Engineering and product co-design enable iterative improvement through deployment, while great products and partner feedback strengthen each other. Products keep us grounded in reality and guide us to solve the most impactful problems with our design partners.",
      "paragraph2": "Empirical and iterative approach to explainable AI is the most effective and reliable measures come from a combination of proactive development and feedback from careful real-world testing with experienced professionals.",
      "paragraph3": "We plan to contribute to AI legitimacy by (1) maintaining a high security bar — preventing attacks, (2) sharing best practices and frameworks for building safe AI systems with our clients, and (3) accelerating new types of certifications on alignment by sharing our new reference standards and agent specifications.",
      "paragraph4": "We believe that methods developed for today's systems, such as effective red-teaming and post-deployment monitoring, provide valuable insights that will extend to future, more explainable systems."
    },
    "measure": {
      "title": "Measure what truly matters",
      "description": "We will focus on understanding how our systems create genuine value in the real world. The most important breakthroughs often come from rethinking our objectives, not just optimizing existing metrics."
    },
    "partners": {
      "title": "Be Design Partners",
      "description": "If you are a law firm or compliance professional interested in becoming a design partner, click here: ",
      "link": "Be Design Partners"
    }
  },
  "nog": {
    "intro": "Right now, clients are asking the eggon team to",
    "actions": [
      "Build AI agents",
      "Prompt engineering",
      "Advise on AI security",
      "Connect AI to data",
      "Deliver AI training"
    ],
    "getExamples": "Get Examples",
    "useCasesAgent": "Use Cases Agent",
    "academyProgram": "IA Academy Program"
  },
// en.json - Nouvelles clés à ajouter dans la section "noglab"
"noglab": {
  "heroPhrase": "→ EggOn Make your",
  "heroDropdownOption": "Future AI",
  "heroTitle": "Make your AI Agents Insurable",
  "heroSubtitle": "We are building a future where professionals, particularly in law, finance, and healthcare, can deploy AI agents that are certified compliant, auditable, and insurable.",
  "heroCta": "Be Design Partner",
  "title": "Make your AI Agents Insurable",
  "intro1": "EggOn Lab is dedicated to the governance and traceability of artificial intelligence agents through a next-generation orchestrator.",
  "intro2": "We are building a future where professionals — especially in law, finance, and healthcare — can deploy AI agents that are certified compliant, auditable, and insurable.",
  "intro3": "We are engineers and builders who have worked for some of the most secure tech companies, including iManage, and for industry leaders as Traceability System Experts and Quality Engineers.",
  "legitimacy": {
    "title": "Legitimacy in AI Is About More Than Right or Wrong Answers",
    "paragraph1": "AI capabilities are advancing at an unprecedented pace, but one major problem remains: opacity.",
    "paragraph2": "This opacity is even more concerning as AI enters sectors that are not like any other industries: justice and healthcare. These are the foundations of a free and fair society.",
    "paragraph3": "Every day, courts make decisions that change the course of human lives. Such decisions demand empathy, experience, and context — but also a process that feels legitimate to those affected.",
    "paragraph4": "No family should ever wonder if they lost custody because of a poorly calibrated algorithm. No patient should ever doubt that their treatment was decided after genuine human evaluation.",
    "paragraph5": "The real issue isn't simply whether AI gives the right or wrong answer — it's doubt. And once doubt sets in, it erodes trust and undermines the legitimacy of our systems."
  },
  "aiForEveryone": {
    "title": "AI That Works for Everyone",
    "paragraph1": "Knowledge of how AI agents operate and make decisions must not remain concentrated in a few labs.",
    "paragraph2": "This lack of transparency slows adoption in high-responsibility professions, and the absence of explainability makes insuring AI-driven processes impossible.",
    "paragraph3": "To bridge this gap, we created N.O.G (Nested Orchestration & Governance) — a platform designed to understand, audit, and certify AI agents."
  },
  "principles": {
    "title": "Solid Legitimacy Matters",
    "explicability": {
      "title": "Explicability",
      "description": "Every task executed by an AI agent must be understandable and explainable. Users must be able to trace the full reasoning and verify its legitimacy."
    },
    "accessibility": {
      "title": "Accessibility",
      "description": "Explainability only matters if it's shared. Results and supporting evidence must be easy to access for everyone impacted by a decision."
    },
    "recall": {
      "title": "Recall",
      "description": "If bias, error, or manipulation is detected, the system must allow for immediate recall — just like product recalls in critical industries. Governed AI should never be irreversible."
    },
    "speed": {
      "title": "Speed",
      "description": "Compliance must not slow innovation. Explainable AI should be as fast as it is powerful, accelerating adoption while building trust."
    }
  },
  "growth": {
    "title": "Growth Step by Step",
    "paragraph1": "Engineering and product co-design enable iterative improvement through deployment, while great products and partner feedback strengthen each other. Products keep us grounded in reality and guide us to solve the most impactful problems with our design partners.",
    "paragraph2": "Empirical and iterative approach to explainable AI is the most effective and reliable measures come from a combination of proactive development and feedback from careful real-world testing with experienced professionals.",
    "paragraph3": "We plan to contribute to AI legitimacy by (1) maintaining a high security bar — preventing attacks, (2) sharing best practices and frameworks for building safe AI systems with our clients, and (3) accelerating new types of certifications on alignment by sharing our new reference standards and agent specifications.",
    "paragraph4": "We believe that methods developed for today's systems, such as effective red-teaming and post-deployment monitoring, provide valuable insights that will extend to future, more explainable systems."
  },
  "measure": {
    "title": "Measure what truly matters",
    "description": "We will focus on understanding how our systems create genuine value in the real world. The most important breakthroughs often come from rethinking our objectives, not just optimizing existing metrics."
  },
  "partners": {
    "title": "Be Design Partners",
    "description": "If you are a law firm or compliance professional interested in becoming a design partner, click here: ",
    "link": "Be Design Partners"
  }
}

// fr.json - Nouvelles clés à ajouter dans la section "noglab"  
"noglab": {
  "heroPhrase": "→ EggOn Rendez vos",
  "heroDropdownOption": "IA Future",
  "heroTitle": "Rendez vos Agents IA Assurables",
  "heroSubtitle": "Nous construisons un avenir où les professionnels, en particulier du droit, de la finance et de la santé, peuvent déployer des agents IA certifiés conformes, auditables et assurables.",
  "heroCta": "Devenir partenaire de conception",
  "title": "Rendez vos Agents IA Assurables",
  "intro1": "EggOn Lab se consacre à la gouvernance et à la traçabilité des agents d'intelligence artificielle grâce à un orchestrateur de nouvelle génération.",
  "intro2": "Nous construisons un avenir où les professionnels — en particulier du droit, de la finance et de la santé — peuvent déployer des agents IA certifiés conformes, auditables et assurables.",
  "intro3": "Nous sommes des ingénieurs et des constructeurs qui ont travaillé pour certaines des entreprises technologiques les plus sécurisées, notamment iManage, et pour des leaders de l'industrie en tant qu'experts en systèmes de traçabilité et ingénieurs qualité.",
  "legitimacy": {
    "title": "La légitimité de l'IA va au-delà des bonnes ou mauvaises réponses",
    "paragraph1": "Les capacités de l'IA progressent à un rythme sans précédent, mais un problème majeur demeure : l'opacité.",
    "paragraph2": "Cette opacité est encore plus préoccupante lorsque l'IA entre dans des secteurs qui ne ressemblent à aucune autre industrie : la justice et la santé. Ce sont les fondements d'une société libre et équitable.",
    "paragraph3": "Chaque jour, les tribunaux prennent des décisions qui changent le cours de vies humaines. De telles décisions exigent de l'empathie, de l'expérience et du contexte — mais aussi un processus qui semble légitime à ceux qui sont affectés.",
    "paragraph4": "Aucune famille ne devrait jamais se demander si elle a perdu la garde à cause d'un algorithme mal calibré. Aucun patient ne devrait jamais douter que son traitement a été décidé après une véritable évaluation humaine.",
    "paragraph5": "Le vrai problème n'est pas simplement de savoir si l'IA donne la bonne ou la mauvaise réponse — c'est le doute. Et une fois que le doute s'installe, il érode la confiance et mine la légitimité de nos systèmes."
  },
  "aiForEveryone": {
    "title": "Une IA qui fonctionne pour tous",
    "paragraph1": "La connaissance du fonctionnement et de la prise de décision des agents IA ne doit pas rester concentrée dans quelques laboratoires.",
    "paragraph2": "Ce manque de transparence ralentit l'adoption dans les professions à haute responsabilité, et l'absence d'explicabilité rend impossible l'assurance des processus pilotés par l'IA.",
    "paragraph3": "Pour combler cette lacune, nous avons créé N.O.G (Nested Orchestration & Governance) — une plateforme conçue pour comprendre, auditer et certifier les agents IA."
  },
  "principles": {
    "title": "Une légitimité solide compte",
    "explicability": {
      "title": "Explicabilité",
      "description": "Chaque tâche exécutée par un agent IA doit être compréhensible et explicable. Les utilisateurs doivent être capables de retracer le raisonnement complet et de vérifier sa légitimité."
    },
    "accessibility": {
      "title": "Accessibilité",
      "description": "L'explicabilité n'a d'importance que si elle est partagée. Les résultats et les preuves à l'appui doivent être faciles d'accès pour tous ceux qui sont impactés par une décision."
    },
    "recall": {
      "title": "Rappel",
      "description": "Si un biais, une erreur ou une manipulation est détectée, le système doit permettre un rappel immédiat — tout comme les rappels de produits dans les industries critiques. L'IA gouvernée ne devrait jamais être irréversible."
    },
    "speed": {
      "title": "Vitesse",
      "description": "La conformité ne doit pas ralentir l'innovation. L'IA explicable devrait être aussi rapide qu'elle est puissante, accélérant l'adoption tout en renforçant la confiance."
    }
  },
  "growth": {
    "title": "Croissance étape par étape",
    "paragraph1": "La co-conception d'ingénierie et de produit permet une amélioration itérative grâce au déploiement, tandis que les excellents produits et les retours de partenaires se renforcent mutuellement. Les produits nous gardent ancrés dans la réalité et nous guident pour résoudre les problèmes les plus impactants avec nos partenaires de conception.",
    "paragraph2": "Une approche empirique et itérative de l'IA explicable est la plus efficace et les mesures fiables proviennent d'une combinaison de développement proactif et de retours de tests soigneux dans le monde réel avec des professionnels expérimentés.",
    "paragraph3": "Nous prévoyons de contribuer à la légitimité de l'IA en (1) maintenant un niveau de sécurité élevé — prévenant les attaques, (2) partageant les meilleures pratiques et cadres pour construire des systèmes IA sûrs avec nos clients, et (3) accélérant de nouveaux types de certifications sur l'alignement en partageant nos nouveaux standards de référence et spécifications d'agents.",
    "paragraph4": "Nous croyons que les méthodes développées pour les systèmes d'aujourd'hui, comme le red-teaming efficace et la surveillance post-déploiement, fournissent des insights précieux qui s'étendront aux futurs systèmes plus explicables."
  },
  "measure": {
    "title": "Mesurer ce qui compte vraiment",
    "description": "Nous nous concentrerons sur la compréhension de la façon dont nos systèmes créent une valeur authentique dans le monde réel. Les percées les plus importantes proviennent souvent de la remise en question de nos objectifs, et non de l'optimisation des métriques existantes."
  },
  "partners": {
    "title": "Devenez partenaires de conception",
    "description": "Si vous êtes un cabinet d'avocats ou un professionnel de la conformité intéressé à devenir un partenaire de conception, cliquez ici : ",
    "link": "Devenez partenaires de conception"
  }
}
// en.json - Nouvelles clés à ajouter dans la section "noglab"
"noglab": {
  "heroPhrase": "→ EggOn Make your",
  "heroDropdownOption": "Future AI",
  "heroTitle": "Make your AI Agents Insurable",
  "heroSubtitle": "We are building a future where professionals, particularly in law, finance, and healthcare, can deploy AI agents that are certified compliant, auditable, and insurable.",
  "heroCta": "Be Design Partner",
  "title": "Make your AI Agents Insurable",
  "intro1": "EggOn Lab is dedicated to the governance and traceability of artificial intelligence agents through a next-generation orchestrator.",
  "intro2": "We are building a future where professionals — especially in law, finance, and healthcare — can deploy AI agents that are certified compliant, auditable, and insurable.",
  "intro3": "We are engineers and builders who have worked for some of the most secure tech companies, including iManage, and for industry leaders as Traceability System Experts and Quality Engineers.",
  "legitimacy": {
    "title": "Legitimacy in AI Is About More Than Right or Wrong Answers",
    "paragraph1": "AI capabilities are advancing at an unprecedented pace, but one major problem remains: opacity.",
    "paragraph2": "This opacity is even more concerning as AI enters sectors that are not like any other industries: justice and healthcare. These are the foundations of a free and fair society.",
    "paragraph3": "Every day, courts make decisions that change the course of human lives. Such decisions demand empathy, experience, and context — but also a process that feels legitimate to those affected.",
    "paragraph4": "No family should ever wonder if they lost custody because of a poorly calibrated algorithm. No patient should ever doubt that their treatment was decided after genuine human evaluation.",
    "paragraph5": "The real issue isn't simply whether AI gives the right or wrong answer — it's doubt. And once doubt sets in, it erodes trust and undermines the legitimacy of our systems."
  },
  "aiForEveryone": {
    "title": "AI That Works for Everyone",
    "paragraph1": "Knowledge of how AI agents operate and make decisions must not remain concentrated in a few labs.",
    "paragraph2": "This lack of transparency slows adoption in high-responsibility professions, and the absence of explainability makes insuring AI-driven processes impossible.",
    "paragraph3": "To bridge this gap, we created N.O.G (Nested Orchestration & Governance) — a platform designed to understand, audit, and certify AI agents."
  },
  "principles": {
    "title": "Solid Legitimacy Matters",
    "explicability": {
      "title": "Explicability",
      "description": "Every task executed by an AI agent must be understandable and explainable. Users must be able to trace the full reasoning and verify its legitimacy."
    },
    "accessibility": {
      "title": "Accessibility",
      "description": "Explainability only matters if it's shared. Results and supporting evidence must be easy to access for everyone impacted by a decision."
    },
    "recall": {
      "title": "Recall",
      "description": "If bias, error, or manipulation is detected, the system must allow for immediate recall — just like product recalls in critical industries. Governed AI should never be irreversible."
    },
    "speed": {
      "title": "Speed",
      "description": "Compliance must not slow innovation. Explainable AI should be as fast as it is powerful, accelerating adoption while building trust."
    }
  },
  "growth": {
    "title": "Growth Step by Step",
    "paragraph1": "Engineering and product co-design enable iterative improvement through deployment, while great products and partner feedback strengthen each other. Products keep us grounded in reality and guide us to solve the most impactful problems with our design partners.",
    "paragraph2": "Empirical and iterative approach to explainable AI is the most effective and reliable measures come from a combination of proactive development and feedback from careful real-world testing with experienced professionals.",
    "paragraph3": "We plan to contribute to AI legitimacy by (1) maintaining a high security bar — preventing attacks, (2) sharing best practices and frameworks for building safe AI systems with our clients, and (3) accelerating new types of certifications on alignment by sharing our new reference standards and agent specifications.",
    "paragraph4": "We believe that methods developed for today's systems, such as effective red-teaming and post-deployment monitoring, provide valuable insights that will extend to future, more explainable systems."
  },
  "measure": {
    "title": "Measure what truly matters",
    "description": "We will focus on understanding how our systems create genuine value in the real world. The most important breakthroughs often come from rethinking our objectives, not just optimizing existing metrics."
  },
  "partners": {
    "title": "Be Design Partners",
    "description": "If you are a law firm or compliance professional interested in becoming a design partner, click here: ",
    "link": "Be Design Partners"
  }
}
  "contact": {
    "title": "Let's Build the Future Together",
    "subtitle": "Ready to make AI agents your competitive advantage? Get in touch with our team.",
    "form": {
      "name": "Name",
      "email": "Email",
      "company": "Company",
      "subject": "Subject",
      "message": "Message",
      "submit": "Send Message",
      "sending": "Sending...",
      "success": "Message sent successfully! We'll get back to you soon.",
      "error": "Failed to send message. Please try again."
    }
  },
  "footer": {
    "copyright": "© EggOn Technology 2025",
    "whyEggon": "Why EggOn",
    "legal": "Legal",
    "aboutUs": "About Us",
    "futureAI": "Future AI",
    "termsOfUse": "Terms of Use",
    "privacyPolicy": "Privacy Policy",
    "cookieChoices": "Cookie Choices",
    "dataProcessing": "Data Processing Agreement",
    "legalNotice": "Legal Notice"
  }
}
