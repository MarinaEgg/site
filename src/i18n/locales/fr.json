{
  "navigation": {
    "home": "Accueil",
    "lab": "Lab",
    "learn": "Apprendre",
    "contact": "Contact"
  },
  "hero": {
    "title": "Faites des agents IA votre avantage concurrentiel",
    "subtitle": "Connectez l'IA en toute sécurité aux connaissances de votre entreprise avec des agents qui planifient, agissent et renforcent chaque équipe avec confiance.",
    "cta": "Commencer à construire",
    "labLink": "EggOn Lab — L'équipe dédiée à rendre les agents IA entièrement assurables."
  },
  "collection": {
    "title": "ÉTUDES DE CAS",
    "subtitle": "Les entreprises choisissent de construire avec EggOn pour un avantage concurrentiel déloyal. Nos agents sont approuvés par des entreprises avant-gardistes dans le juridique, l'aérospatiale et la finance. Restez informé — demandez un devis.",
    "cta": "Obtenir un devis"
  },
  "legalStack": {
    "subtitle": "POURQUOI EGGON",
    "title": "Faites confiance à une équipe experte dans votre domaine",
    "description": "Eggon combine une expertise juridique approfondie avec une véritable ingénierie IA pour fournir des solutions intégrées et fiables adaptées à vos défis opérationnels.",
    "stackTitle": "LA PILE D'AGENTS JURIDIQUES"
  },
  "learn": {
    "title": "EggOn Lab en action",
    "intro1": "EggOn Lab se consacre à la gouvernance et à la traçabilité des agents d'intelligence artificielle grâce à un orchestrateur de nouvelle génération.",
    "intro2": "Nous construisons un avenir où les professionnels — en particulier du droit, de la finance et de la santé — peuvent déployer des agents IA certifiés conformes, auditables et assurables.",
    "intro3": "Nous sommes des ingénieurs et des constructeurs qui ont travaillé pour certaines des entreprises technologiques les plus sécurisées, notamment iManage, et pour des leaders de l'industrie en tant qu'experts en systèmes de traçabilité et ingénieurs qualité.",
    "legitimacy": {
      "title": "La légitimité de l'IA va au-delà des bonnes ou mauvaises réponses",
      "paragraph1": "Les capacités de l'IA progressent à un rythme sans précédent, mais un problème majeur demeure : l'opacité.",
      "paragraph2": "Cette opacité est encore plus préoccupante lorsque l'IA entre dans des secteurs qui ne ressemblent à aucune autre industrie : la justice et la santé. Ce sont les fondements d'une société libre et équitable.",
      "paragraph3": "Chaque jour, les tribunaux prennent des décisions qui changent le cours de vies humaines. De telles décisions exigent de l'empathie, de l'expérience et du contexte — mais aussi un processus qui semble légitime à ceux qui sont affectés.",
      "paragraph4": "Aucune famille ne devrait jamais se demander si elle a perdu la garde à cause d'un algorithme mal calibré. Aucun patient ne devrait jamais douter que son traitement a été décidé après une véritable évaluation humaine.",
      "paragraph5": "Le vrai problème n'est pas simplement de savoir si l'IA donne la bonne ou la mauvaise réponse — c'est le doute. Et une fois que le doute s'installe, il érode la confiance et mine la légitimité de nos systèmes."
    },
    "aiForEveryone": {
      "title": "Une IA qui fonctionne pour tous",
      "paragraph1": "La connaissance du fonctionnement et de la prise de décision des agents IA ne doit pas rester concentrée dans quelques laboratoires.",
      "paragraph2": "Ce manque de transparence ralentit l'adoption dans les professions à haute responsabilité, et l'absence d'explicabilité rend impossible l'assurance des processus pilotés par l'IA.",
      "paragraph3": "Pour combler cette lacune, nous avons créé N.O.G (Nested Orchestration & Governance) — une plateforme conçue pour comprendre, auditer et certifier les agents IA."
    },
    "principles": {
      "title": "Une légitimité solide compte",
      "explicability": {
        "title": "Explicabilité",
        "description": "Chaque tâche exécutée par un agent IA doit être compréhensible et explicable. Les utilisateurs doivent être capables de retracer le raisonnement complet et de vérifier sa légitimité."
      },
      "accessibility": {
        "title": "Accessibilité",
        "description": "L'explicabilité n'a d'importance que si elle est partagée. Les résultats et les preuves à l'appui doivent être faciles d'accès pour tous ceux qui sont impactés par une décision."
      },
      "recall": {
        "title": "Rappel",
        "description": "Si un biais, une erreur ou une manipulation est détectée, le système doit permettre un rappel immédiat — tout comme les rappels de produits dans les industries critiques. L'IA gouvernée ne devrait jamais être irréversible."
      },
      "speed": {
        "title": "Vitesse",
        "description": "La conformité ne doit pas ralentir l'innovation. L'IA explicable devrait être aussi rapide qu'elle est puissante, accélérant l'adoption tout en renforçant la confiance."
      }
    },
    "growth": {
      "title": "Croissance étape par étape",
      "paragraph1": "La co-conception d'ingénierie et de produit permet une amélioration itérative grâce au déploiement, tandis que les excellents produits et les retours de partenaires se renforcent mutuellement. Les produits nous gardent ancrés dans la réalité et nous guident pour résoudre les problèmes les plus impactants avec nos partenaires de conception.",
      "paragraph2": "Une approche empirique et itérative de l'IA explicable est la plus efficace et les mesures fiables proviennent d'une combinaison de développement proactif et de retours de tests soigneux dans le monde réel avec des professionnels expérimentés.",
      "paragraph3": "Nous prévoyons de contribuer à la légitimité de l'IA en (1) maintenant un niveau de sécurité élevé — prévenant les attaques, (2) partageant les meilleures pratiques et cadres pour construire des systèmes IA sûrs avec nos clients, et (3) accélérant de nouveaux types de certifications sur l'alignement en partageant nos nouveaux standards de référence et spécifications d'agents.",
      "paragraph4": "Nous croyons que les méthodes développées pour les systèmes d'aujourd'hui, comme le red-teaming efficace et la surveillance post-déploiement, fournissent des insights précieux qui s'étendront aux futurs systèmes plus explicables."
    },
    "measure": {
      "title": "Mesurer ce qui compte vraiment",
      "description": "Nous nous concentrerons sur la compréhension de la façon dont nos systèmes créent une valeur authentique dans le monde réel. Les percées les plus importantes proviennent souvent de la remise en question de nos objectifs, et non de l'optimisation des métriques existantes."
    },
    "partners": {
      "title": "Devenez partenaires de conception",
      "description": "Si vous êtes un cabinet d'avocats ou un professionnel de la conformité intéressé à devenir un partenaire de conception, cliquez ici : ",
      "link": "Devenez partenaires de conception"
    }
  },
  "nog": {
    "intro": "En ce moment, les clients demandent à l'équipe eggon de",
    "actions": [
      "Construire des agents IA",
      "Ingénierie de prompts",
      "Conseiller sur la sécurité IA",
      "Connecter l'IA aux données",
      "Fournir une formation IA"
    ],
    "getExamples": "Obtenir des exemples",
    "useCasesAgent": "Agent de cas d'usage",
    "academyProgram": "Programme Académie IA"
  },
  "noglab": {
    "title": "EggOn Lab en action",
    "intro1": "EggOn Lab se consacre à la gouvernance et à la traçabilité des agents d'intelligence artificielle grâce à un orchestrateur de nouvelle génération.",
    "intro2": "Nous construisons un avenir où les professionnels — en particulier du droit, de la finance et de la santé — peuvent déployer des agents IA certifiés conformes, auditables et assurables.",
    "intro3": "Nous sommes des ingénieurs et des constructeurs qui ont travaillé pour certaines des entreprises technologiques les plus sécurisées, notamment iManage, et pour des leaders de l'industrie en tant qu'experts en systèmes de traçabilité et ingénieurs qualité.",
    "legitimacy": {
      "title": "La légitimité de l'IA va au-delà des bonnes ou mauvaises réponses",
      "paragraph1": "Les capacités de l'IA progressent à un rythme sans précédent, mais un problème majeur demeure : l'opacité.",
      "paragraph2": "Cette opacité est encore plus préoccupante lorsque l'IA entre dans des secteurs qui ne ressemblent à aucune autre industrie : la justice et la santé. Ce sont les fondements d'une société libre et équitable.",
      "paragraph3": "Chaque jour, les tribunaux prennent des décisions qui changent le cours de vies humaines. De telles décisions exigent de l'empathie, de l'expérience et du contexte — mais aussi un processus qui semble légitime à ceux qui sont affectés.",
      "paragraph4": "Aucune famille ne devrait jamais se demander si elle a perdu la garde à cause d'un algorithme mal calibré. Aucun patient ne devrait jamais douter que son traitement a été décidé après une véritable évaluation humaine.",
      "paragraph5": "Le vrai problème n'est pas simplement de savoir si l'IA donne la bonne ou la mauvaise réponse — c'est le doute. Et une fois que le doute s'installe, il érode la confiance et mine la légitimité de nos systèmes."
    },
    "aiForEveryone": {
      "title": "Une IA qui fonctionne pour tous",
      "paragraph1": "La connaissance du fonctionnement et de la prise de décision des agents IA ne doit pas rester concentrée dans quelques laboratoires.",
      "paragraph2": "Ce manque de transparence ralentit l'adoption dans les professions à haute responsabilité, et l'absence d'explicabilité rend impossible l'assurance des processus pilotés par l'IA.",
      "paragraph3": "Pour combler cette lacune, nous avons créé N.O.G (Nested Orchestration & Governance) — une plateforme conçue pour comprendre, auditer et certifier les agents IA."
    },
    "principles": {
      "title": "Une légitimité solide compte",
      "explicability": {
        "title": "Explicabilité",
        "description": "Chaque tâche exécutée par un agent IA doit être compréhensible et explicable. Les utilisateurs doivent être capables de retracer le raisonnement complet et de vérifier sa légitimité."
      },
      "accessibility": {
        "title": "Accessibilité",
        "description": "L'explicabilité n'a d'importance que si elle est partagée. Les résultats et les preuves à l'appui doivent être faciles d'accès pour tous ceux qui sont impactés par une décision."
      },
      "recall": {
        "title": "Rappel",
        "description": "Si un biais, une erreur ou une manipulation est détectée, le système doit permettre un rappel immédiat — tout comme les rappels de produits dans les industries critiques. L'IA gouvernée ne devrait jamais être irréversible."
      },
      "speed": {
        "title": "Vitesse",
        "description": "La conformité ne doit pas ralentir l'innovation. L'IA explicable devrait être aussi rapide qu'elle est puissante, accélérant l'adoption tout en renforçant la confiance."
      }
    },
    "growth": {
      "title": "Croissance étape par étape",
      "paragraph1": "La co-conception d'ingénierie et de produit permet une amélioration itérative grâce au déploiement, tandis que les excellents produits et les retours de partenaires se renforcent mutuellement. Les produits nous gardent ancrés dans la réalité et nous guident pour résoudre les problèmes les plus impactants avec nos partenaires de conception.",
      "paragraph2": "Une approche empirique et itérative de l'IA explicable est la plus efficace et les mesures fiables proviennent d'une combinaison de développement proactif et de retours de tests soigneux dans le monde réel avec des professionnels expérimentés.",
      "paragraph3": "Nous prévoyons de contribuer à la légitimité de l'IA en (1) maintenant un niveau de sécurité élevé — prévenant les attaques, (2) partageant les meilleures pratiques et cadres pour construire des systèmes IA sûrs avec nos clients, et (3) accélérant de nouveaux types de certifications sur l'alignement en partageant nos nouveaux standards de référence et spécifications d'agents.",
      "paragraph4": "Nous croyons que les méthodes développées pour les systèmes d'aujourd'hui, comme le red-teaming efficace et la surveillance post-déploiement, fournissent des insights précieux qui s'étendront aux futurs systèmes plus explicables."
    },
    "measure": {
      "title": "Mesurer ce qui compte vraiment",
      "description": "nous nous concentrerons sur la compréhension de la façon dont nos systèmes créent une valeur authentique dans le monde réel. Les percées les plus importantes proviennent souvent de la remise en question de nos objectifs, et non de l'optimisation des métriques existantes."
    },
    "partners": {
      "title": "Devenez partenaires de conception",
      "description": "Si vous êtes un cabinet d'avocats ou un professionnel de la conformité intéressé à devenir un partenaire de conception, cliquez ici : ",
      "link": "Devenez partenaires de conception"
    }
  },
  "contact": {
    "title": "Construisons l'avenir ensemble",
    "subtitle": "Prêt à faire des agents IA votre avantage concurrentiel ? Contactez notre équipe.",
    "form": {
      "name": "Nom",
      "email": "Email",
      "company": "Entreprise",
      "subject": "Sujet",
      "message": "Message",
      "submit": "Envoyer le message",
      "sending": "Envoi en cours...",
      "success": "Message envoyé avec succès ! Nous vous répondrons bientôt.",
      "error": "Échec de l'envoi du message. Veuillez réessayer."
    }
  },
  "footer": {
    "copyright": "© EggOn Technology 2025",
    "whyEggon": "Pourquoi EggOn",
    "legal": "Légal",
    "aboutUs": "À propos",
    "futureAI": "IA du futur",
    "termsOfUse": "Conditions d'utilisation",
    "privacyPolicy": "Politique de confidentialité",
    "cookieChoices": "Choix des cookies",
    "dataProcessing": "Accord de traitement des données",
    "legalNotice": "Mentions légales"
  }
}